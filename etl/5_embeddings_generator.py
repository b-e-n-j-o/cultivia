"""
Ce script g√©n√®re des embeddings pour une liste d'√©v√©nements en utilisant l'API OpenAI. Il prend en entr√©e un fichier JSON 
contenant des √©v√©nements pr√©par√©s, cr√©e des embeddings via le mod√®le text-embedding-3-small, et sauvegarde les r√©sultats 
dans trois fichiers distincts : un fichier NPZ pour les embeddings, un fichier JSON pour les m√©tadonn√©es, et un fichier JSON 
pour les √©v√©nements ayant √©chou√©. Le script g√®re automatiquement les limites de taux d'API et inclut un syst√®me de r√©essai 
en cas d'√©chec.

√âtapes du processus :
1. Chargement des variables d'environnement et v√©rification de la cl√© API OpenAI
2. Initialisation du g√©n√©rateur d'embeddings avec la cl√© API
3. Lecture du fichier JSON contenant les √©v√©nements pr√©par√©s
4. Pour chaque √©v√©nement :
   - Extraction du texte √† transformer en embedding
   - Appel √† l'API OpenAI avec gestion des erreurs et des limites de taux
   - Stockage de l'embedding et des m√©tadonn√©es associ√©es
5. Sauvegarde des r√©sultats :
   - Embeddings au format NPZ (numpy compress√©)
   - M√©tadonn√©es au format JSON
   - Liste des √©v√©nements √©chou√©s au format JSON
"""

import pandas as pd
import json
import time
import numpy as np
from openai import OpenAI, RateLimitError
from tqdm import tqdm
from typing import List, Dict, Tuple, Optional
import os
from dotenv import load_dotenv
from datetime import datetime
from pathlib import Path

TODAY = datetime.now().strftime("%Y-%m-%d")

class EventEmbeddingsGenerator:
    def __init__(self, openai_api_key: str):
        if not openai_api_key:
            raise ValueError("üîë API key OpenAI manquante")
        self.client = OpenAI(api_key=openai_api_key)
        self.retry_delay = 1
        
    def create_embedding(self, text: str, max_retries: int = 3) -> Optional[List[float]]:
        for attempt in range(max_retries):
            try:
                response = self.client.embeddings.create(
                    input=text.strip(),
                    model="text-embedding-3-small"
                )
                self.retry_delay = 1
                return response.data[0].embedding
                
            except RateLimitError:
                wait_time = self.retry_delay * (2 ** attempt)
                print(f"‚è≥ Limite de taux atteinte, attente de {wait_time}s...")
                time.sleep(wait_time)
                self.retry_delay = wait_time
                
            except Exception as e:
                print(f"‚ùå Erreur embedding (tentative {attempt + 1}/{max_retries}): {str(e)}")
                if attempt == max_retries - 1:
                    return None
                time.sleep(self.retry_delay)
        
        return None

    def generate_events_embeddings(self, prepared_events: List[Dict]) -> Tuple[pd.DataFrame, List[Dict]]:
        embeddings = []
        failed_events = []
        
        progress_bar = tqdm(prepared_events, desc="üîÑ G√©n√©ration embeddings", 
                          unit="evt", ncols=100, disable=not os.isatty(0))
        
        for event in progress_bar:
            try:
                event_id = event.get('uuid', 'unknown')
                progress_bar.set_description(f"üîÑ Traitement: {event_id[:8]}")
                
                if not event.get('embedding_text'):
                    raise ValueError("Texte d'embedding manquant")
                
                embedding = self.create_embedding(event['embedding_text'])
                if embedding is None:
                    raise Exception("√âchec de cr√©ation de l'embedding")
                
                # Copier toutes les m√©tadonn√©es de l'√©v√©nement et ajouter l'embedding
                event_data = event.copy()
                event_data['embedding'] = embedding
                event_data['id'] = len(embeddings)  # Ajouter un ID s√©quentiel
                embeddings.append(event_data)
                
                progress_bar.set_postfix({
                    "‚úÖ": len(embeddings),
                    "‚ùå": len(failed_events)
                })
                
            except Exception as e:
                failed_event = {
                    'uuid': event_id,
                    'error': str(e),
                    'embedding_text': event.get('embedding_text', '')[:100]
                }
                failed_events.append(failed_event)
                print(f"\n‚ùå √âchec pour {event_id}: {str(e)}")
        
        df = pd.DataFrame(embeddings)
        return df, failed_events

    def save_results(self, df: pd.DataFrame, failed_events: List[Dict], save_path: str):
        print("\nüíæ Sauvegarde des r√©sultats...")
        save_path = Path(save_path)
        save_path.mkdir(parents=True, exist_ok=True)
        
        with tqdm(total=3, desc="üìÅ Sauvegarde", disable=not os.isatty(0)) as pbar:
            embeddings_array = np.array(df['embedding'].tolist())
            np.savez_compressed(
                save_path / f'embeddings_{TODAY}.npz',
                embeddings=embeddings_array
            )
            pbar.update(1)
            
            metadata = df.drop('embedding', axis=1).to_dict('records')
            with open(save_path / f'metadata_{TODAY}.json', 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            pbar.update(1)
            
            if failed_events:
                with open(save_path / f'failed_{TODAY}.json', 'w', encoding='utf-8') as f:
                    json.dump(failed_events, f, ensure_ascii=False, indent=2)
            pbar.update(1)

def run_events_pipeline(prepared_events_path: str, openai_api_key: str, save_path: str) -> Optional[pd.DataFrame]:
    print("üöÄ D√©marrage du pipeline")
    
    try:
        if not os.path.exists(prepared_events_path):
            raise FileNotFoundError(f"Fichier non trouv√©: {prepared_events_path}")
            
        with open(prepared_events_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        prepared_events = data.get('events', [])
        if not prepared_events:
            raise ValueError("Aucun √©v√©nement trouv√© dans le fichier")
            
        print(f"‚úÖ {len(prepared_events)} √©v√©nements charg√©s")
        
        generator = EventEmbeddingsGenerator(openai_api_key)
        df, failed_events = generator.generate_events_embeddings(prepared_events)
        
        success_rate = (len(df)/len(prepared_events))*100
        print(f"\nüìä R√©sultats:")
        print(f"üìå Total: {len(prepared_events)}")
        print(f"‚úÖ R√©ussis: {len(df)} ({success_rate:.1f}%)")
        print(f"‚ùå √âchou√©s: {len(failed_events)}")
        
        if len(df) > 0:
            generator.save_results(df, failed_events, save_path)
            return df
        else:
            print("‚ö†Ô∏è Aucun embedding g√©n√©r√©")
            return None
            
    except Exception as e:
        print(f"‚ùå Erreur pipeline: {str(e)}")
        return None

if __name__ == "__main__":
    load_dotenv()
    
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    if not OPENAI_API_KEY:
        raise ValueError("API key manquante dans .env")
        
    PREPARED_EVENTS_PATH = f"../data/json_prepared/{TODAY}.json"
    SAVE_PATH = f"../data/embeddings/{TODAY}"
    
    df = run_events_pipeline(PREPARED_EVENTS_PATH, OPENAI_API_KEY, SAVE_PATH)